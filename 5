# Import the necessary libraries
import pandas as pd
from xgboost import XGBClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

# Load the data into a Pandas dataframe
df = pd.read_csv('data.csv')

# Split the data into features and labels
X = df.drop(columns='phenotype')
y = df['phenotype']

# Split the data into a training set and a test set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# Train an XGBoost classifier on the training data
xgb_clf = XGBClassifier()
xgb_clf.fit(X_train, y_train)

# Make predictions on the test data using the XGBoost classifier
xgb_predictions = xgb_clf.predict(X_test)

# Calculate the accuracy of the XGBoost classifier
xgb_accuracy = sum(xgb_predictions == y_test) / len(y_test)
print(f'XGBoost accuracy: {xgb_accuracy:.2f}')

# Train a random forest classifier on the training data
rf_clf = RandomForestClassifier()
rf_clf.fit(X_train, y_train)

# Make predictions on the test data using the random forest classifier
rf_predictions = rf_clf.predict(X_test)

# Calculate the accuracy of the random forest classifier
rf_accuracy = sum(rf_predictions == y_test) / len(y_test)
print(f'Random Forest accuracy: {rf_accuracy:.2f}')
